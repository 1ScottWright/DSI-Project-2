{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and initial EDA Workbook for Project 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The purpose of this workbook is to load the raw data for the project and to clean variables.  It is set up so that if new variables need attention, it starts from the raw data and produces all the changes from the beginning.  In this way, it is clear that our source is the initial raw file.  \n",
    "\n",
    "I flipped between this workbook and another, more EDA focused workbook.  As EDA discovered items to look at, features to build, etc, I modified the datafiles accordingly.  \n",
    "\n",
    "At the end of the notebook, csv files are generated so that other notebooks can pick up the cleaned data and use them as required.  \n",
    "\n",
    "Input:  test.csv and train.csv  \n",
    "Output:  test_nonulls#.csv and train_nonulls#.csv\n",
    "\n",
    "The variable `out_numb` should be updated each time a new data file is generated.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import math\n",
    "\n",
    "pd.options.display.max_columns = 999             # Allows viewing of more rows and columns in a dataframe\n",
    "pd.options.display.max_rows = 999\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testfile = './datasets/test.csv'\n",
    "df_test = pd.read_csv(testfile)\n",
    "\n",
    "trainfile = './datasets/train.csv'\n",
    "df = pd.read_csv(trainfile)\n",
    "\n",
    "out_numb = '6'\n",
    "outfile_train = './datasets/train_nonulls' + out_numb + '.csv'\n",
    "outfile_test = './datasets/test_nonulls' + out_numb + '.csv'\n",
    "\n",
    "#sample_out = './sample_sub_reg.csv'\n",
    "#df_out = pd.read_csv(sample_out)\n",
    "\n",
    "#print(len(df), len(df_test), len(df_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lot Frontage \n",
    "Lot frontage should not be 0.  To estimate a value for lot frontage when missing, I am assuming that a relationship exists between the amount of 'Lot Frontage' and the 'Lot Area'.  Below, I find the mean of the various ratios of Lot Frontage to Lot Area.  I then apply that average to the Lot Area in the case that Lot Frontage is not available.\n",
    "\n",
    "There were two different ways to estimatet this amount.  I used 0.0079 as the estimate and sensitivity tested using 0.0071.  There was not a material difference in my results based on the sensitivity test.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df['Lot Frontage'].notnull()]['Lot Frontage'].sum() / (df[df['Lot Frontage'].notnull()]['Lot Area'].sum()))\n",
    "print(np.mean(df[df['Lot Frontage'].notnull()]['Lot Frontage'] / df[df['Lot Frontage'].notnull()]['Lot Area']))\n",
    "\n",
    "df.loc[df['Lot Frontage'].isnull(), 'Lot Frontage'] = df[df['Lot Frontage'].isnull()]['Lot Area']*0.0076\n",
    "df_test.loc[df_test['Lot Frontage'].isnull(), 'Lot Frontage'] = df_test[df_test['Lot Frontage'].isnull()]['Lot Area']*0.0076"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alley\n",
    "\n",
    "The data dictionary allows NA as a response indicating no alley -- change this to a more descriptive NoAlley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Alley'].isnull(), 'Alley'] = 'NoAlley'\n",
    "df_test.loc[df_test['Alley'].isnull(), 'Alley'] = 'NoAlley'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Masonry Type and Area\n",
    "\n",
    "The data dictionary allows None as a response indicating no masonry -- change this to a more descriptive NoMasonryType and 0 (for Mas Vnr Area)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Mas Vnr Type'].isnull(), 'Mas Vnr Type'] = 'NoMasonryType'\n",
    "df.loc[df['Mas Vnr Area'].isnull(), 'Mas Vnr Area'] = 0\n",
    "df_test.loc[df_test['Mas Vnr Type'].isnull(), 'Mas Vnr Type'] = 'NoMasonryType'\n",
    "df_test.loc[df_test['Mas Vnr Area'].isnull(), 'Mas Vnr Area'] = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basement fields.  \n",
    "\n",
    "Note first need to record no basement values and for exposure and type 2.  There will be some additional work after that. Again, n/a or none was a valid entry that caused python to interpret this as a null.  For numerical values, I assumed 0 and for other cases, I created a 'NoB' identifier meaning 'No Basement'\n",
    "\n",
    "Bsmt Qual            55  \n",
    "Bsmt Cond            55  \n",
    "Bsmt Exposure        58  \n",
    "BsmtFin Type 1       55  \n",
    "BsmtFin SF 1          1  \n",
    "BsmtFin Type 2       56  \n",
    "BsmtFin SF 2          1  \n",
    "Bsmt Unf SF           1  \n",
    "Total Bsmt SF         1  \n",
    "Bsmt Full Bath        2  \n",
    "Bsmt Half Bath        2  \n",
    "\n",
    "Assumed that if a BsmtFin Type 2 is null, that it could use the value in BsmtFin Type 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Bsmt Qual'].isnull(), ['Bsmt Qual', \n",
    "                                  'Bsmt Cond', \n",
    "                                  'Bsmt Exposure', \n",
    "                                  'BsmtFin Type 1',\n",
    "                                  'BsmtFin Type 2']] = 'NoB'     # No basement\n",
    "\n",
    "df.loc[df['Bsmt Exposure'].isnull(), 'Bsmt Exposure'] = 'NoEx'\n",
    "df.loc[df['BsmtFin Type 2'].isnull(), 'BsmtFin Type 2'] = df.loc[df['BsmtFin Type 2'].isnull(), 'BsmtFin Type 1']\n",
    "df.loc[df['BsmtFin SF 1'].isnull(), 'BsmtFin SF 1'] = 0\n",
    "df.loc[df['BsmtFin SF 2'].isnull(), 'BsmtFin SF 2'] = 0\n",
    "df.loc[df['Bsmt Unf SF'].isnull(), 'Bsmt Unf SF'] = 0\n",
    "df.loc[df['Total Bsmt SF'].isnull(), 'Total Bsmt SF'] = 0\n",
    "\n",
    "\n",
    "df_test.loc[df_test['Bsmt Qual'].isnull(), ['Bsmt Qual', 'Bsmt Cond', 'Bsmt Exposure', 'BsmtFin Type 1','BsmtFin Type 2']] = 'NoB'\n",
    "df_test.loc[df_test['Bsmt Exposure'].isnull(), 'Bsmt Exposure'] = 'NoEx'\n",
    "df_test.loc[df_test['BsmtFin Type 2'].isnull(), 'BsmtFin Type 2'] = df_test.loc[df['BsmtFin Type 2'].isnull(), 'BsmtFin Type 1']\n",
    "df_test.loc[df_test['BsmtFin SF 1'].isnull(), 'BsmtFin SF 1'] = 0\n",
    "df_test.loc[df_test['BsmtFin SF 2'].isnull(), 'BsmtFin SF 2'] = 0\n",
    "df_test.loc[df_test['Bsmt Unf SF'].isnull(), 'Bsmt Unf SF'] = 0\n",
    "df_test.loc[df_test['Total Bsmt SF'].isnull(), 'Total Bsmt SF'] = 0\n",
    "\n",
    "df.loc[df['Bsmt Full Bath'].isnull(), 'Bsmt Full Bath'] = 0\n",
    "df.loc[df['Bsmt Half Bath'].isnull(), 'Bsmt Half Bath'] = 0\n",
    "\n",
    "df_test.loc[df['Bsmt Full Bath'].isnull(), 'Bsmt Full Bath'] = 0\n",
    "df_test.loc[df['Bsmt Half Bath'].isnull(), 'Bsmt Half Bath'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fireplace Quality \n",
    "\n",
    "The data dictionary allows an n/a for fireplace quality.  \n",
    "\n",
    "I created a new value 'NoF' for 'No Fireplace' in these situations.   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Fireplace Qu'].isnull(), 'Fireplace Qu'] = 'NoF'\n",
    "df_test.loc[df_test['Fireplace Qu'].isnull(), 'Fireplace Qu'] = 'NoF'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Garage variables\n",
    "\n",
    "The data dictionary allows N/A for no garage  \n",
    "\n",
    "For most, the values should be set to none.  I used 'NoGarage' for text columns and 0 for numerical columns.  \n",
    "For the item that's left, I imputed values based on averages / most prevalent\n",
    "\n",
    "- Garage Type         113\n",
    "- Garage Yr Blt       114\n",
    "- Garage Finish       114\n",
    "- Garage Cars           1\n",
    "- Garage Area           1\n",
    "- Garage Qual         114\n",
    "- Garage Cond         114"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Garage Type'].isnull(), ['Garage Yr Blt']] = 0\n",
    "df.loc[df['Garage Type'].isnull(), ['Garage Type', 'Garage Finish', 'Garage Qual','Garage Cond']] = 'NoGarage'\n",
    "\n",
    "df_test.loc[df['Garage Type'].isnull(), ['Garage Yr Blt']] = 0       \n",
    "df_test.loc[df_test['Garage Type'].isnull(), ['Garage Type', 'Garage Finish', 'Garage Qual','Garage Cond']] = 'NoGarage'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "For one record, there are not values even though (through EDA), there was a detached garage.  It doesn't really matter what we put here since it's only one record, I decided to query the other records and put in the mean value of the population.  In this case, year build = 1962, cars = 2 and square footage = 420.  Since there is a garage but it is not recorded, I assumed \"low quality\" metrics for the text variables (unfinished and TA).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df['Garage Type']=='Detchd']['Garage Yr Blt'].mean())\n",
    "print(df[df['Garage Type']=='Detchd']['Garage Cars'].mean())\n",
    "print(df[df['Garage Type']=='Detchd']['Garage Area'].mean())\n",
    "#round these estimates and use to fill in missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Garage Yr Blt'].isnull(), 'Garage Yr Blt'] = 1962\n",
    "df.loc[df['Garage Finish'].isnull(), 'Garage Finish'] = 'Unf'\n",
    "df.loc[df['Garage Cars'].isnull(), 'Garage Cars'] = 2\n",
    "df.loc[df['Garage Area'].isnull(), 'Garage Area'] = 420\n",
    "df.loc[df['Garage Qual'].isnull(), 'Garage Qual'] = 'TA'\n",
    "df.loc[df['Garage Cond'].isnull(), 'Garage Cond'] = 'TA'\n",
    "\n",
    "\n",
    "df_test.loc[df_test['Garage Yr Blt'].isnull(), 'Garage Yr Blt'] = 1962\n",
    "df_test.loc[df_test['Garage Finish'].isnull(), 'Garage Finish'] = 'Unf'\n",
    "df_test.loc[df_test['Garage Cars'].isnull(), 'Garage Cars'] = 2\n",
    "df_test.loc[df_test['Garage Area'].isnull(), 'Garage Area'] = 420\n",
    "df_test.loc[df_test['Garage Qual'].isnull(), 'Garage Qual'] = 'TA'\n",
    "df_test.loc[df_test['Garage Cond'].isnull(), 'Garage Cond'] = 'TA'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remaining null values\n",
    "\n",
    "- Pool QC            2042\n",
    "- Fence              1651\n",
    "- Misc Feature       1986\n",
    "- Electrical            1\n",
    "\n",
    "These each have N/A as an option and they were all text.  I used a new category indicating \"NoXYZ\" instead of the data dictionary N/A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Pool QC'].isnull(), 'Pool QC'] = 'NoPool'\n",
    "df.loc[df['Fence'].isnull(), 'Fence'] = 'NoFence'\n",
    "df.loc[df['Misc Feature'].isnull(), 'Misc Feature'] = 'NoMiscF'\n",
    "\n",
    "df_test.loc[df_test['Pool QC'].isnull(), 'Pool QC'] = 'NoPool'\n",
    "df_test.loc[df_test['Fence'].isnull(), 'Fence'] = 'NoFence'\n",
    "df_test.loc[df_test['Misc Feature'].isnull(), 'Misc Feature'] = 'NoMiscF'\n",
    "df_test.loc[df_test['Electrical'].isnull(), 'Electrical'] = 'SBrkr'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Features\n",
    "\n",
    "---\n",
    "\n",
    "I thought it might be instructive to use the maximum of the year built, the year remodeled, or garage added as a potential indication of when substantive improvements to the property were enacted.  New varialbe 'Yr Latest Change' added to the data frame.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Yr Latest Change'] = df[['Garage Yr Blt','Year Built', 'Year Remod/Add', ]].max(axis = 1)\n",
    "df_test['Yr Latest Change'] = df_test[['Garage Yr Blt','Year Built', 'Year Remod/Add', ]].max(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "The neighborhood variable is likely not usefull with as many neighborhoods involved.  I decided to group the neighborhoods by average sales price to create new categories.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Neighborhood'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neigh_cat(list_in):\n",
    "    list_out = []\n",
    "    cat1 = ['StoneBr','NridgHt','NoRidge']\n",
    "    cat2 = ['GrnHill','Veenker','Timber']\n",
    "    cat3 = ['Somerst','ClearCr','Crawfor','CollgCr', 'Blmngtn']\n",
    "    cat4 = ['NWAmes','Gilbert','Greens','SawyerW']\n",
    "    cat5 = ['Mitchel','NAmes','Blueste']\n",
    "    cat6 = ['NPkVill','Sawyer','Landmrk','SWISU','Edwards','BrkSide', 'OldTown']\n",
    "    cat7 = ['BrDale','IDOTRR','MeadowV']\n",
    "    for each in list_in:\n",
    "        if each in cat1:\n",
    "            list_out.append('cat1')\n",
    "        elif each in cat2:\n",
    "            list_out.append('cat2')\n",
    "        elif each in cat3:\n",
    "            list_out.append('cat3')\n",
    "        elif each in cat4:\n",
    "            list_out.append('cat4')\n",
    "        elif each in cat5:\n",
    "            list_out.append('cat5')\n",
    "        elif each in cat6:\n",
    "            list_out.append('cat6')\n",
    "        elif each in cat7:\n",
    "            list_out.append('cat7')\n",
    "        else:\n",
    "            list_out.append(each)\n",
    "    return(list_out)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Neighb feat'] = get_neigh_cat(df['Neighborhood'])\n",
    "df_test['Neighb feat'] = get_neigh_cat(df_test['Neighborhood'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "For this iteration of data files, I have decided to take the log of certain items that are skewed right.  Lot frontage, lot area, gr living area, and total bsmt SF.  In the modeling notebook, I will make two other changes, MS SubClass turned into category variable, and exclude other SF variables.  For log function, need the python function that allows log(0)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#var_list = ['Lot Frontage', 'Lot Area', 'Gr Liv Area', 'Total Bsmt SF']\n",
    "\n",
    "#for each in var_list:\n",
    "#    df[each] = np.log1p(df[each])\n",
    "#    df_test[each] = np.log1p(df[each])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(df.isnull().sum()))\n",
    "print(sum(df_test.isnull().sum()))\n",
    "\n",
    "#df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output cleansed data into new data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(outfile_train, index = False)\n",
    "df_test.to_csv(outfile_test, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
