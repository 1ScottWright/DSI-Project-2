{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2 Model Workbook (Lasso / Kaggle / Friday)\n",
    "\n",
    "---\n",
    "I used this workbook to run models with various levels of variables and one of three transformations on the target y:  log(y), 1/log(y), and 1/y.  Overall this didn't improve my Kaggle score, which is what I was focused on during Friday's work.\n",
    "\n",
    "---\n",
    "Import cleaned data from prior steps.  \n",
    "Select columns for model.  \n",
    "Add dummies.  \n",
    "Add polynomial features.  \n",
    "Standard Scale  \n",
    "And then run various models\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, LinearRegression, RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleantrain = './datasets/train_nonulls8.csv'\n",
    "cleantest =  './datasets/test_nonulls8.csv'\n",
    "\n",
    "df = pd.read_csv(cleantrain)\n",
    "df_test = pd.read_csv(cleantest)\n",
    "\n",
    "y = df['SalePrice']                             # For train, save SalePrice in new var\n",
    "df.drop('SalePrice', axis =1, inplace = True)   # For train, drop SalePrice and use new var\n",
    "Id_y_hat = df_test['Id']                        # Save Ids for Kaggle output\n",
    "train_Id = df['Id']                             # Save Ids from train data (need?)\n",
    "\n",
    "y = 1/y                                 # y is skewed, taking log transform helps\n",
    "\n",
    "# print(df.shape)\n",
    "# print(df_test.shape)\n",
    "# print(len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dummies\n",
    "---\n",
    "The functions below are tools to more easily allow for the addition of dummy variables to data.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code puts all columns names of non-numeric values into one variable\n",
    "def get_dummy_list(df_in):\n",
    "    a = df_in.dtypes == 'object'\n",
    "    col_list_all = df_in.columns\n",
    "    b = len(col_list_all)\n",
    "    features = []\n",
    "    for each in range(b):\n",
    "        if a[each]:\n",
    "            features.append(col_list_all[each])\n",
    "    return(features)\n",
    "\n",
    "# This takes a list of variables in and a dataframe.  It outputs the dataframe with dummy columns added\n",
    "def add_dummies(dlist, df_in):\n",
    "    df_out = pd.get_dummies(df_in, columns = dlist, drop_first = True)\n",
    "    return(df_out)\n",
    "\n",
    "# After dummy variables are created, the text based variables need to be removed from the data.\n",
    "def remove_text_var(df_in):\n",
    "    a = df_in.dtypes != 'object'\n",
    "    col_list_all = df_in.columns\n",
    "    b = len(col_list_all)\n",
    "    features = []\n",
    "    for each in range(b):\n",
    "        if a[each]:\n",
    "            features.append(col_list_all[each])\n",
    "    return(df_in[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polynomial Additions\n",
    "---\n",
    "The following functions make it easier to add polynomial variables to the data.  \n",
    "A list of lists gets passed in as long as a dataframe.  \n",
    "In this way, polynomial additions can be added by groups of variables rather than in one huge mass.  \n",
    "The unify function is needed as well in case the dummies or polynomials results in different columns for train versus test data.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_poly(var_list, df_in):\n",
    "    df_slice = df_in[var_list]                           #only poly the variables in list\n",
    "    poly = PolynomialFeatures(2, include_bias = True, interaction_only=True)\n",
    "    poly.fit(df_slice)\n",
    "    new_vals = poly.transform(df_slice)\n",
    "    new_names = poly.get_feature_names(df_slice.columns)\n",
    "    a = dict(zip(new_names,new_vals.T))\n",
    "    for each in a:\n",
    "        df_in[each] = a[each]\n",
    "    return(df_in)\n",
    "\n",
    "def unify_columns(df1, df2):\n",
    "    clist1 = set(df1.columns)\n",
    "    clist2 = set(df2.columns)\n",
    "    master_list = clist1.union(clist2)\n",
    "    add_to_1 = list(master_list - clist1)\n",
    "    add_to_2 = list(master_list - clist2)\n",
    "  \n",
    "    if len(add_to_1) > 0:\n",
    "        for each in add_to_1:\n",
    "            df1[each] = 0\n",
    "    \n",
    "    if len(add_to_2) > 0:\n",
    "        for each in add_to_2:\n",
    "            df2[each] = 0\n",
    "\n",
    "    return (df1.sort_index(axis = 1), df2.sort_index(axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Selection\n",
    "---\n",
    "The next section brings together the data and calls the functions above to create the dataset that will go into the regression.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_all = df.columns\n",
    "\n",
    "# These are dropped from model before considering correlations\n",
    "# Generally they are columns that have been zeroed out from LassoCV.\n",
    "# I've iterated through columns using top correlated in, Lasso out, etc.\n",
    "\n",
    "cols_to_exclude = [\n",
    "#                   'Low Qual Fin SF', '2nd Flr SF', '1st Flr SF',\n",
    "#                   'BsmtFin SF 1', 'BsmtFin SF 2',\n",
    "#                   'Misc Val', 'Misc Feature',\n",
    "                   'Id', 'PID'\n",
    "#                   'Garage Area', 'Garage Cars','Full Bath',\n",
    "#                   'TotRms AbvGrd', 'Garage Yr Blt'\n",
    "                  ]\n",
    "\n",
    "\n",
    "cols_in = col_all.drop(cols_to_exclude)\n",
    "\n",
    "train_model = df[cols_in]                                #only take cols_in into model\n",
    "test_model = df_test[cols_in]\n",
    "\n",
    "train_model = train_model.astype({\"MS SubClass\":str})    #This numeric column is a category\n",
    "test_model = test_model.astype({\"MS SubClass\":str})      #If done in dataprep, it would\n",
    "train_model = train_model.astype({\"Mo Sold\":str})        #have reversed when re-read\n",
    "test_model = test_model.astype({\"Mo Sold\":str})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "feat = get_dummy_list(train_model)                        #Add dummies for all non-numeric\n",
    "feat.remove('Neighborhood')                               #Except I want my feature based on Neigh, not Neigh\n",
    "train_model = add_dummies(feat, train_model)               \n",
    "test_model = add_dummies(feat, test_model)\n",
    "\n",
    "train_model = remove_text_var(train_model)                #remove non-numeric variable\n",
    "test_model = remove_text_var(test_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The section below are the polynomial variables that the user wants to include in the model.  User input required.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "#poly_list = [['Full Bath', 'Half Bath'],\n",
    "#             ['Garage Cars', 'Garage Area'],\n",
    "#             ['Wood Deck SF', 'Open Porch SF', 'Screen Porch'],\n",
    "#             ['Bsmt Unf SF', 'BsmtFin SF 1', 'BsmtFin SF 2'],\n",
    "#             ['1st Flr SF', '2nd Flr SF', 'Gr Liv Area', 'TotRms AbvGrd'] ,\n",
    "#             ['Year Built','Year Remod/Add','Yr Latest Change']\n",
    "#            ]\n",
    "\n",
    "#poly_list = [poly_all]\n",
    "\n",
    "# Runs 20 on:\n",
    "# poly_list = [['Garage Cars', 'Garage Area'],\n",
    "#              ['Bsmt Unf SF', 'BsmtFin SF 1', 'BsmtFin SF 2'],\n",
    "#              ['1st Flr SF', '2nd Flr SF', 'Gr Liv Area', 'TotRms AbvGrd']\n",
    "#             ]\n",
    "\n",
    "poly_list = [\n",
    "            ['1st Flr SF', '2nd Flr SF', 'Gr Liv Area', 'TotRms AbvGrd'],\n",
    "             ['Wood Deck SF', 'Open Porch SF', 'Screen Porch'],\n",
    "             ['Garage Cars', 'Garage Area'],\n",
    "             ['Full Bath', 'Half Bath'],\n",
    "             ['Bsmt Unf SF', 'BsmtFin SF 1', 'BsmtFin SF 2']\n",
    "            ]\n",
    "\n",
    "for each in poly_list:\n",
    "    train_model = add_poly(each, train_model)\n",
    "    test_model = add_poly(each, test_model)\n",
    "\n",
    "\n",
    "train_model, test_model = unify_columns(train_model, test_model)       # create columns where needed so cols match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "The final step in pullling together the model is to make final variable selections.  I have chosen to pick those based on correlations (positive and negative) from all of the feature prep work above.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "numb_vars = 145  # Actually twice this number of variables will be included.\n",
    "\n",
    "top_corr = list(pd.concat([train_model, y], axis = 1).corr()['SalePrice'].sort_values(ascending = False).index[1:numb_vars+1])\n",
    "top_neg_corr = list(pd.concat([train_model, y], axis = 1).corr()['SalePrice'].sort_values(ascending = True).index[0:numb_vars])\n",
    "\n",
    "train_model_f = train_model[top_corr].copy()                 \n",
    "test_model_f = test_model[top_corr].copy()                  \n",
    "\n",
    "train_model_f[top_neg_corr] = train_model[top_neg_corr]          #final train data\n",
    "test_model_f[top_neg_corr] = test_model[top_neg_corr]            #final test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split\n",
    "Now that the data is set up, we split the \"train\" dataset into train/test components so that we can test various modeling techniques.  Once a model is in shape to produce Kaggle output, the test_model above, the full train_model above will be used to calibrate the model and the test_model input will be used to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_model_f, y, random_state = 1929)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To make sure the data is in good shape, run all cells above this point.  Select models to run and analyze below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso without Pipeline - Using to Zero In on Kaggle Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "ss.fit(X_train)\n",
    "X_train_ss = ss.transform(X_train)\n",
    "X_test_ss = ss.transform(X_test)\n",
    "train_f = ss.transform(train_model_f)\n",
    "test_f = ss.transform(test_model_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "ls = LassoCV(max_iter=10000, cv=2, n_alphas = 500)\n",
    "ls.fit(X_train_ss, y_train)\n",
    "\n",
    "n += 1\n",
    "ns = '0'*(n<10) + str(n)\n",
    "print(ns)\n",
    "\n",
    "#ytrain = np.exp(1/ls.predict(X_train_ss))\n",
    "#ytest = np.exp(1/ls.predict(X_test_ss))\n",
    "#ykaggle = np.exp(1/ls.predict(test_f))\n",
    "\n",
    "\n",
    "#ytrain = np.exp(ls.predict(X_train_ss))\n",
    "#ytest = np.exp(ls.predict(X_test_ss))\n",
    "#ykaggle = np.exp(ls.predict(test_f))\n",
    "\n",
    "# ytrain = (ls.predict(X_train_ss))\n",
    "# ytest = ls.predict(X_test_ss)\n",
    "# ykaggle = ls.predict(test_f)\n",
    "\n",
    "ytrain = 1/(ls.predict(X_train_ss))\n",
    "ytest = 1/ls.predict(X_test_ss)\n",
    "ykaggle = 1/ls.predict(test_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual y's re-transformed\n",
    "A_y_train =(1/y_train)\n",
    "A_y_test = (1/y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.648951282780468e-07\n",
      "0.7281324307046508\n",
      "0.7067477477582707\n"
     ]
    }
   ],
   "source": [
    "print(ls.alpha_)\n",
    "print(r2_score(ytrain, A_y_train ))\n",
    "print(r2_score(ytest,A_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 92194.26565224, 153392.41362789, 194913.51966602,  97553.04578572,\n",
       "       159686.1498723 ])"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ykaggle[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store fit results systematically\n",
    "var1 = ns +'_train'\n",
    "var2 = ns +'_test'\n",
    "results[var1] = r2_score(ytrain, A_y_train)\n",
    "results[var2] = r2_score(ytest,A_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'01_test': 0.8820455601866684,\n",
       " '01_train': 0.9343717741830373,\n",
       " '02_test': 0.870407407104832,\n",
       " '02_train': 0.9170755319994874,\n",
       " '03_test': 0.851336843690979,\n",
       " '03_train': 0.8908876023241936,\n",
       " '04_test': 0.8810922173597352,\n",
       " '04_train': 0.9278445119966676,\n",
       " '05_test': 0.8820455601866684,\n",
       " '05_train': 0.9343717741830373,\n",
       " '06_test': 0.8820133907177033,\n",
       " '06_train': 0.9349582618135205,\n",
       " '07_test': 0.8822502257738419,\n",
       " '07_train': 0.935353966696235,\n",
       " '08_test': 0.8629402961916399,\n",
       " '08_train': 0.9167370516277821,\n",
       " '09_test': 0.8854261749335861,\n",
       " '09_train': 0.9333126493935868,\n",
       " '10_test': 0.8822912486437898,\n",
       " '10_train': 0.9349383919301046,\n",
       " '11_test': 0.8815219338853812,\n",
       " '11_train': 0.9360313999586102,\n",
       " '12_test': 0.8556696632833527,\n",
       " '12_train': 0.895638865953223,\n",
       " '13_test': 0.8101145025114722,\n",
       " '13_train': 0.4420531868467207,\n",
       " '14_test': 0.7055343733827828,\n",
       " '14_train': 0.7258285054374725,\n",
       " '15_test': 0.7067477477582707,\n",
       " '15_train': 0.7281324307046508}"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up systematically store predictions\n",
    "ytrain_df[ns] = ytrain\n",
    "ytest_df[ns] = ytest\n",
    "yka_df[ns] = ykaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "numb = 'fri07'\n",
    "outfileb = './submissions/'+numb+'.csv'\n",
    "out_to_kaggle = pd.DataFrame({'Id':Id_y_hat, 'SalePrice':(1/3)*(yka_df['10']+yka_df['07']+yka_df['15'])})\n",
    "out_to_kaggle.to_csv(outfileb, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# obj0, obj1, obj2 are created here...\n",
    "\n",
    "# Saving the objects:\n",
    "with open('objs.pkl', 'w') as f:  # Python 3: open(..., 'wb')\n",
    "    pickle.dump([obj0, obj1, obj2], f)\n",
    "\n",
    "# Getting back the objects:\n",
    "with open('objs.pkl') as f:  # Python 3: open(..., 'rb')\n",
    "    obj0, obj1, obj2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('friday_variables', 'wb') as fileout:\n",
    "    pickle.dump([yka_df, ytrain_df, ytest_df, results], fileout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up systematically store predictions\n",
    "\n",
    "ytrain_df = pd.DataFrame({\n",
    "    \"05\":y_05_train,\n",
    "    \"06\":ytrain\n",
    "})\n",
    "\n",
    "ytest_df = pd.DataFrame({\n",
    "    \"05\":y_05_test,\n",
    "    \"06\":ytest\n",
    "})\n",
    "yka_df = pd.DataFrame({\n",
    "    \"05\":y_05_kaggle,\n",
    "    \"06\":ykaggle\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>05</th>\n",
       "      <th>06</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>194948.279274</td>\n",
       "      <td>194486.035567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105825.928871</td>\n",
       "      <td>105118.848421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>194348.418859</td>\n",
       "      <td>194096.032580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>147722.627878</td>\n",
       "      <td>150598.874421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>160407.139049</td>\n",
       "      <td>160915.671212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>413637.865897</td>\n",
       "      <td>415197.561074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>207896.128094</td>\n",
       "      <td>209619.443596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>379441.001666</td>\n",
       "      <td>378559.193455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>171762.178196</td>\n",
       "      <td>170435.771367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>147461.321910</td>\n",
       "      <td>146884.098325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>168299.254467</td>\n",
       "      <td>168894.616443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>367092.504527</td>\n",
       "      <td>367408.040408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>157065.894502</td>\n",
       "      <td>157562.732715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>44353.173647</td>\n",
       "      <td>44816.814460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>125665.296254</td>\n",
       "      <td>126168.829808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>95670.533007</td>\n",
       "      <td>93766.626883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>183448.394118</td>\n",
       "      <td>183438.403966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>307697.724340</td>\n",
       "      <td>307207.109543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>154319.241809</td>\n",
       "      <td>155158.890178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>145426.974374</td>\n",
       "      <td>146243.749766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>233332.408517</td>\n",
       "      <td>233504.290572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>194151.551223</td>\n",
       "      <td>194636.572100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>270871.498307</td>\n",
       "      <td>270709.417400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>207231.703163</td>\n",
       "      <td>207486.035436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>132537.639953</td>\n",
       "      <td>132577.611811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>118754.467762</td>\n",
       "      <td>119656.450216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>214879.869201</td>\n",
       "      <td>213836.184542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>133895.748614</td>\n",
       "      <td>133294.919383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>109559.095025</td>\n",
       "      <td>109644.335815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>129170.965710</td>\n",
       "      <td>129789.536552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1508</th>\n",
       "      <td>117442.237934</td>\n",
       "      <td>116769.371404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>103619.896438</td>\n",
       "      <td>103882.121703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>111039.644977</td>\n",
       "      <td>111043.661786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>92562.981376</td>\n",
       "      <td>91910.974637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>138129.521607</td>\n",
       "      <td>137691.528853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>323477.449072</td>\n",
       "      <td>321275.208984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>56271.212980</td>\n",
       "      <td>56210.738844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>85395.106684</td>\n",
       "      <td>85920.364427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>114707.562926</td>\n",
       "      <td>116678.048013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>87234.829912</td>\n",
       "      <td>86697.999089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518</th>\n",
       "      <td>285930.784214</td>\n",
       "      <td>285407.035117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519</th>\n",
       "      <td>208473.178505</td>\n",
       "      <td>213523.146400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>185776.723384</td>\n",
       "      <td>186063.339219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>135952.645379</td>\n",
       "      <td>136649.415630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>224265.402832</td>\n",
       "      <td>224199.897754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>367378.366816</td>\n",
       "      <td>365068.344907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>261895.304662</td>\n",
       "      <td>262194.571756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>138594.367505</td>\n",
       "      <td>137687.186248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>121593.838073</td>\n",
       "      <td>120532.420140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>200296.007483</td>\n",
       "      <td>201216.250067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>127899.979524</td>\n",
       "      <td>128181.443895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529</th>\n",
       "      <td>380043.979978</td>\n",
       "      <td>379133.957535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>199562.238843</td>\n",
       "      <td>201002.169826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531</th>\n",
       "      <td>138357.489925</td>\n",
       "      <td>138376.828490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>124205.954173</td>\n",
       "      <td>123901.459172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1533</th>\n",
       "      <td>217072.134973</td>\n",
       "      <td>216857.878761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1534</th>\n",
       "      <td>109119.302775</td>\n",
       "      <td>108978.413690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535</th>\n",
       "      <td>294131.948762</td>\n",
       "      <td>293567.118855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>197073.472353</td>\n",
       "      <td>196474.698415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1537</th>\n",
       "      <td>249972.472965</td>\n",
       "      <td>250168.729240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1538 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 05             06\n",
       "0     194948.279274  194486.035567\n",
       "1     105825.928871  105118.848421\n",
       "2     194348.418859  194096.032580\n",
       "3     147722.627878  150598.874421\n",
       "4     160407.139049  160915.671212\n",
       "5     413637.865897  415197.561074\n",
       "6     207896.128094  209619.443596\n",
       "7     379441.001666  378559.193455\n",
       "8     171762.178196  170435.771367\n",
       "9     147461.321910  146884.098325\n",
       "10    168299.254467  168894.616443\n",
       "11    367092.504527  367408.040408\n",
       "12    157065.894502  157562.732715\n",
       "13     44353.173647   44816.814460\n",
       "14    125665.296254  126168.829808\n",
       "15     95670.533007   93766.626883\n",
       "16    183448.394118  183438.403966\n",
       "17    307697.724340  307207.109543\n",
       "18    154319.241809  155158.890178\n",
       "19    145426.974374  146243.749766\n",
       "20    233332.408517  233504.290572\n",
       "21    194151.551223  194636.572100\n",
       "22    270871.498307  270709.417400\n",
       "23    207231.703163  207486.035436\n",
       "24    132537.639953  132577.611811\n",
       "25    118754.467762  119656.450216\n",
       "26    214879.869201  213836.184542\n",
       "27    133895.748614  133294.919383\n",
       "28    109559.095025  109644.335815\n",
       "29    129170.965710  129789.536552\n",
       "...             ...            ...\n",
       "1508  117442.237934  116769.371404\n",
       "1509  103619.896438  103882.121703\n",
       "1510  111039.644977  111043.661786\n",
       "1511   92562.981376   91910.974637\n",
       "1512  138129.521607  137691.528853\n",
       "1513  323477.449072  321275.208984\n",
       "1514   56271.212980   56210.738844\n",
       "1515   85395.106684   85920.364427\n",
       "1516  114707.562926  116678.048013\n",
       "1517   87234.829912   86697.999089\n",
       "1518  285930.784214  285407.035117\n",
       "1519  208473.178505  213523.146400\n",
       "1520  185776.723384  186063.339219\n",
       "1521  135952.645379  136649.415630\n",
       "1522  224265.402832  224199.897754\n",
       "1523  367378.366816  365068.344907\n",
       "1524  261895.304662  262194.571756\n",
       "1525  138594.367505  137687.186248\n",
       "1526  121593.838073  120532.420140\n",
       "1527  200296.007483  201216.250067\n",
       "1528  127899.979524  128181.443895\n",
       "1529  380043.979978  379133.957535\n",
       "1530  199562.238843  201002.169826\n",
       "1531  138357.489925  138376.828490\n",
       "1532  124205.954173  123901.459172\n",
       "1533  217072.134973  216857.878761\n",
       "1534  109119.302775  108978.413690\n",
       "1535  294131.948762  293567.118855\n",
       "1536  197073.472353  196474.698415\n",
       "1537  249972.472965  250168.729240\n",
       "\n",
       "[1538 rows x 2 columns]"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
